{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library installation"
      ],
      "metadata": {
        "id": "HcmEel2YLA_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyg0z65pS-Mc",
        "outputId": "8a9ffb5b-f130-4400-ecb9-d3fc4d6a1ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and object creation"
      ],
      "metadata": {
        "id": "5OKoPfcWLGOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "# update your API key here\n",
        "API_KEY = \""\n",
        "client = Groq(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "5wyBa3KgDRdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model execution with input prompt"
      ],
      "metadata": {
        "id": "Vpw87woiLYHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"you are helpful assistance\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"what is LLM ?\",\n",
        "        }\n",
        "]"
      ],
      "metadata": {
        "id": "cuhGqecJLUSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=prompt,\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wilw2WsNTdtQ",
        "outputId": "6962ec62-a1fa-45cf-f634-e823039851f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM stands for Large Language Model. It refers to a type of artificial intelligence (AI) designed to process and understand human language at a large scale. LLMs are trained on vast amounts of text data, which enables them to learn patterns, relationships, and structures of language.\n",
            "\n",
            "Large Language Models are typically based on deep learning architectures, such as transformers, and are trained using self-supervised learning techniques. This means that they learn to predict the next word in a sentence or to fill in missing words, without being explicitly told what the correct answer is.\n",
            "\n",
            "Some key features of LLMs include:\n",
            "\n",
            "1. **Language understanding**: LLMs can comprehend and interpret human language, including nuances, context, and subtleties.\n",
            "2. **Text generation**: LLMs can generate coherent and natural-sounding text, including articles, stories, and conversations.\n",
            "3. **Language translation**: LLMs can translate text from one language to another, often with high accuracy.\n",
            "4. **Sentiment analysis**: LLMs can analyze text to determine the sentiment, emotion, or tone behind it.\n",
            "\n",
            "LLMs have many applications, including:\n",
            "\n",
            "1. **Virtual assistants**: LLMs power virtual assistants like Siri, Alexa, and Google Assistant.\n",
            "2. **Language translation software**: LLMs are used in Google Translate and other language translation tools.\n",
            "3. **Chatbots**: LLMs are used to build chatbots that can have conversations with humans.\n",
            "4. **Content generation**: LLMs can generate content, such as articles, social media posts, and product descriptions.\n",
            "\n",
            "Examples of LLMs include:\n",
            "\n",
            "1. **BERT** (Bidirectional Encoder Representations from Transformers)\n",
            "2. **RoBERTa** (Robustly optimized BERT approach)\n",
            "3. **Transformer-XL** (Extra-Large Transformer)\n",
            "4. **LLaMA** (Large Language Model Meta AI)\n",
            "\n",
            "I hope this helps! Do you have any other questions about LLMs?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWntraNzMBtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
